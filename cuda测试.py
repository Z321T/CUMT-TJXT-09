import torch
import time
import numpy as np


def comprehensive_gpu_test():
    """ GPU ç»¼åˆæ€§èƒ½æµ‹è¯•"""
    print("=== GPU æ€§èƒ½æµ‹è¯• ===\n")

    device = torch.device("cuda")
    print(f"æµ‹è¯•è®¾å¤‡: {torch.cuda.get_device_name(0)}")
    print(f"æ˜¾å­˜æ€»é‡: {torch.cuda.get_device_properties(0).total_memory / 1024 ** 3:.1f} GB")
    print(f"CUDA ç‰ˆæœ¬: {torch.version.cuda}")
    print(f"PyTorch ç‰ˆæœ¬: {torch.__version__}\n")

    # 1. åŸºç¡€çŸ©é˜µè¿ç®—æ€§èƒ½
    print("1. çŸ©é˜µè¿ç®—æ€§èƒ½æµ‹è¯•:")
    sizes = [1024, 2048, 4096, 8192]

    for size in sizes:
        # GPU æµ‹è¯•
        a = torch.randn(size, size, device=device)
        b = torch.randn(size, size, device=device)

        # é¢„çƒ­
        for _ in range(3):
            _ = torch.mm(a, b)
        torch.cuda.synchronize()

        # æ­£å¼æµ‹è¯•
        start_time = time.time()
        for _ in range(10):
            result = torch.mm(a, b)
        torch.cuda.synchronize()
        end_time = time.time()

        avg_time = (end_time - start_time) / 10 * 1000  # ms
        flops = 2 * size ** 3 * 10  # 10æ¬¡æ“ä½œçš„æ€»FLOPS
        tflops = flops / (end_time - start_time) / 1e12

        print(f"   {size}x{size}: {avg_time:.2f} ms/æ¬¡, {tflops:.2f} TFLOPS")

    # 2. æ··åˆç²¾åº¦æµ‹è¯•
    print("\n2. æ··åˆç²¾åº¦ (FP16) æµ‹è¯•:")
    size = 4096
    a_fp32 = torch.randn(size, size, device=device)
    b_fp32 = torch.randn(size, size, device=device)
    a_fp16 = a_fp32.half()
    b_fp16 = b_fp32.half()

    # FP32
    torch.cuda.synchronize()
    start = time.time()
    result_fp32 = torch.mm(a_fp32, b_fp32)
    torch.cuda.synchronize()
    fp32_time = time.time() - start

    # FP16
    torch.cuda.synchronize()
    start = time.time()
    result_fp16 = torch.mm(a_fp16, b_fp16)
    torch.cuda.synchronize()
    fp16_time = time.time() - start

    speedup = fp32_time / fp16_time
    print(f"   FP32: {fp32_time * 1000:.2f} ms")
    print(f"   FP16: {fp16_time * 1000:.2f} ms")
    print(f"   FP16 åŠ é€Ÿæ¯”: {speedup:.2f}x")

    # 3. æ·±åº¦å­¦ä¹ æ¨¡æ‹Ÿæµ‹è¯•
    print("\n3. æ·±åº¦å­¦ä¹ æ¨¡æ‹Ÿæµ‹è¯•:")

    # æ¨¡æ‹Ÿå·ç§¯ç½‘ç»œ
    conv_layers = [
        torch.nn.Conv2d(3, 64, 3, padding=1),
        torch.nn.Conv2d(64, 128, 3, padding=1),
        torch.nn.Conv2d(128, 256, 3, padding=1),
        torch.nn.Conv2d(256, 512, 3, padding=1),
    ]

    for layer in conv_layers:
        layer = layer.to(device)

    batch_sizes = [1, 8, 16, 32]
    input_size = 224

    for batch_size in batch_sizes:
        x = torch.randn(batch_size, 3, input_size, input_size, device=device)

        torch.cuda.synchronize()
        start = time.time()

        # å‰å‘ä¼ æ’­
        for layer in conv_layers:
            x = layer(x)
            x = torch.relu(x)
            x = torch.max_pool2d(x, 2)

        torch.cuda.synchronize()
        end = time.time()

        throughput = batch_size / (end - start)
        print(f"   Batch size {batch_size:2d}: {(end - start) * 1000:.2f} ms, {throughput:.1f} imgs/sec")

    # 4. å†…å­˜å¸¦å®½æµ‹è¯•
    print("\n4. æ˜¾å­˜å¸¦å®½æµ‹è¯•:")
    sizes_mb = [100, 500, 1000, 2000]

    for size_mb in sizes_mb:
        elements = size_mb * 1024 * 1024 // 4  # float32
        data = torch.randn(elements, device=device)

        torch.cuda.synchronize()
        start = time.time()

        # å†…å­˜å¤åˆ¶æµ‹è¯•
        for _ in range(10):
            data_copy = data.clone()

        torch.cuda.synchronize()
        end = time.time()

        bandwidth = (size_mb * 10 * 2) / (end - start) / 1024  # GB/s (è¯»+å†™)
        print(f"   {size_mb} MB: {bandwidth:.1f} GB/s")

    # 5. Transformer æ¨¡æ‹Ÿæµ‹è¯•
    print("\n5. Transformer æ³¨æ„åŠ›æœºåˆ¶æµ‹è¯•:")

    seq_lengths = [512, 1024, 2048]
    d_model = 768
    num_heads = 12

    for seq_len in seq_lengths:
        # æ¨¡æ‹Ÿå¤šå¤´æ³¨æ„åŠ›
        batch_size = 8
        q = torch.randn(batch_size, num_heads, seq_len, d_model // num_heads, device=device)
        k = torch.randn(batch_size, num_heads, seq_len, d_model // num_heads, device=device)
        v = torch.randn(batch_size, num_heads, seq_len, d_model // num_heads, device=device)

        torch.cuda.synchronize()
        start = time.time()

        # æ³¨æ„åŠ›è®¡ç®—
        scores = torch.matmul(q, k.transpose(-2, -1)) / np.sqrt(d_model // num_heads)
        attn_weights = torch.softmax(scores, dim=-1)
        output = torch.matmul(attn_weights, v)

        torch.cuda.synchronize()
        end = time.time()

        print(f"   åºåˆ—é•¿åº¦ {seq_len}: {(end - start) * 1000:.2f} ms")


def memory_stress_test():
    """æ˜¾å­˜å‹åŠ›æµ‹è¯•"""
    print("\n=== æ˜¾å­˜å‹åŠ›æµ‹è¯• ===")

    device = torch.device("cuda")
    total_memory = torch.cuda.get_device_properties(0).total_memory / 1024 ** 3
    print(f"æ˜¾å¡æ€»æ˜¾å­˜: {total_memory:.1f} GB")

    # é€æ­¥å¢åŠ æ˜¾å­˜ä½¿ç”¨
    tensors = []
    allocated_gb = 0

    try:
        while allocated_gb < total_memory * 0.9:  # ä½¿ç”¨90%æ˜¾å­˜
            # æ¯æ¬¡åˆ†é… 100MB
            tensor = torch.randn(100 * 1024 * 1024 // 4, device=device)
            tensors.append(tensor)
            allocated_gb += 0.1

            current_allocated = torch.cuda.memory_allocated() / 1024 ** 3
            print(f"\rå·²åˆ†é…æ˜¾å­˜: {current_allocated:.1f} GB", end="", flush=True)

    except RuntimeError as e:
        if "out of memory" in str(e):
            print(f"\næ˜¾å­˜ä¸è¶³ï¼Œæœ€å¤§å¯ç”¨: {torch.cuda.memory_allocated() / 1024 ** 3:.1f} GB")
        else:
            print(f"\né”™è¯¯: {e}")

    # æ¸…ç†æ˜¾å­˜
    del tensors
    torch.cuda.empty_cache()
    print(f"\næ˜¾å­˜å·²æ¸…ç†")


if __name__ == "__main__":
    if torch.cuda.is_available():
        comprehensive_gpu_test()
        memory_stress_test()
        print(f"\nğŸ‰ æ€§èƒ½æµ‹è¯•å®Œæˆï¼")
    else:
        print("âŒ CUDA ä¸å¯ç”¨")